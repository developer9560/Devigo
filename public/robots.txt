# https://www.robotstxt.org/robotstxt.html
# Allow all web crawlers (like Googlebot) to access all content
User-agent: *
Allow: /

# Sitemap location
Sitemap: https://devigo.in/sitemap.xml

# Disallow crawling of admin or non-relevant pages
Disallow: /admin/
Disallow: /api/
Disallow: /login
Disallow: /logout
Disallow: */preview*
Disallow: */temp*
